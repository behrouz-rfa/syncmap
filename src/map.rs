use std::borrow::Borrow;
use std::collections::HashMap;
use std::fmt;
use std::fmt::{Debug, Formatter};
use std::hash::{BuildHasher, Hash, Hasher};
use std::ops::Deref;
use std::sync::atomic::{AtomicIsize, AtomicUsize, Ordering};
use std::sync::Mutex;
use seize::{Collector, Guard};
use crate::entry::Entry;
use crate::reclaim::{Atomic, Shared};

macro_rules! load_factor {
    ($n: expr) => {
        // Â¾ n = n - n/4 = n - (n >> 2)
        $n - ($n >> 2)
    };
}

pub struct Map<K, V, S = crate::DefaultHashBuilder> {
    read: Atomic<ReadOnly<K, V>>,
    dirty: Atomic<HashMap<K, *mut Entry<V>>>,
    misses: AtomicUsize,
    flag_ctl: AtomicIsize,
    build_hasher: S,
    collector: Collector,
    lock: Mutex<()>

}

impl<K, V, S> fmt::Debug for Map<K, V, S>
    where
        K: Debug,
        V: Debug,
{
    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
        let guard = self.collector.enter();
        f.debug_map().finish()
    }
}

impl<K, V, S> Clone for Map<K, V, S>
    where
        K: Sync + Send + Clone + Hash + Ord,
        V: Sync + Send + Clone,
        S: BuildHasher + Clone,
{
    fn clone(&self) -> Map<K, V, S> {
        let mut cloned_map = Map::with_hasher(self.build_hasher.clone());

        {
            let guard = self.collector.enter();
            let cloned_guard = cloned_map.collector.enter();
            let dirty = self.dirty.load(Ordering::SeqCst, &guard);
            if !dirty.is_null() {
                for (key, value) in unsafe { dirty.deref() }.deref() {
                    let value = unsafe { (value.as_ref().unwrap()).p.load(Ordering::SeqCst, &guard).deref().deref() };
                    cloned_map.insert(key.clone(), value.clone(), &cloned_guard)
                }
            }
        }
        cloned_map
    }
}

impl<K, V> Map<K, V, crate::DefaultHashBuilder> {
    /// Creates an empty `HashMap`.
    ///
    /// The hash map is initially created with a capacity of 0, so it will not allocate until it
    /// is first inserted into.
    ///
    /// # Examples
    ///
    /// ```
    ///
    /// use syncmap::map::Map;
    /// let map: Map<&str, i32> = Map::new();
    /// ```
    pub fn new() -> Self {
        Self::default()
    }
}

impl<K, V, S> Default for Map<K, V, S>
    where
        S: Default,
{
    fn default() -> Self {
        Self::with_hasher(S::default())
    }
}

impl<K, V, S> Map<K, V, S> {
    /// Creates an empty map which will use `hash_builder` to hash keys.
    ///
    /// The created map has the default initial capacity.
    ///
    /// Warning: `hash_builder` is normally randomly generated, and is designed to
    /// allow the map to be resistant to attacks that cause many collisions and
    /// very poor performance. Setting it manually using this
    /// function can expose a DoS attack vector.
    ///
    /// # Examples
    ///
    /// ```
    ///
    /// use syncmap::DefaultHashBuilder;
    /// use syncmap::map::Map;
    /// let map = Map::with_hasher(DefaultHashBuilder::default());
    /// map.pin().insert(1, 2);
    /// ```
    pub fn with_hasher(hash_builder: S) -> Self {
        Self {
            read: Atomic::null(),
            dirty: Atomic::null(),
            misses: AtomicUsize::new(0),
            flag_ctl: AtomicIsize::new(0),
            build_hasher: hash_builder,
            collector: Collector::new(),
            lock: Mutex::new(())
        }
    }

    /// Pin a `Guard` for use with this map.
    ///
    /// Keep in mind that for as long as you hold onto this `Guard`, you are preventing the
    /// collection of garbage generated by the map.
    pub fn guard(&self) -> Guard<'_> {
        self.collector.enter()
    }

    #[inline]
    fn check_guard(&self, guard: &Guard<'_>) {
        // guard.collector() may be `None` if it is unprotected
        if let Some(c) = guard.collector() {
            assert!(Collector::ptr_eq(c, &self.collector));
        }
    }

    fn init_table<'g>(&'g self, guard: &'g Guard<'_>) -> Shared<'g, ReadOnly<K, V>> {
        loop {
            let table = self.read.load(Ordering::SeqCst, guard);
            // safety: we loaded the ReadOnly while the thread was marked as active.
            // ReadOnly won't be deallocated until the guard is dropped at the earliest.
            if !table.is_null() {
                break table;
            }
            //try allocate ReadOnly
            let mut flag = self.flag_ctl.load(Ordering::SeqCst);
            if flag < 0 {
                //lost tje init race; just spin
                std::thread::yield_now();
                continue;
            }

            if self.flag_ctl
                .compare_exchange(flag, -1, Ordering::SeqCst, Ordering::Relaxed).is_ok() {
                let mut table = self.read.load(Ordering::SeqCst, guard);
                if table.is_null() {
                    let n = if flag > 0 {
                        flag as usize
                    } else {
                        1
                    };
                    table = Shared::boxed(ReadOnly::new(), &self.collector);
                    self.read.store(table, Ordering::SeqCst);
                    let m = Shared::boxed(HashMap::new(), &self.collector);
                    self.dirty.store(m, Ordering::SeqCst);
                    flag = load_factor!(n as isize)
                }
                self.flag_ctl.store(flag, Ordering::SeqCst);
                break table;
            }
        }
    }
}

impl<K, V, S> Map<K, V, S>
    where
        K: Clone + Hash + Ord,
        S: BuildHasher,
{
    #[inline]
    fn hash<Q: ?Sized + Hash>(&self, key: &Q) -> u64 {
        let mut h = self.build_hasher.build_hasher();
        key.hash(&mut h);
        h.finish()
    }

    /// Returns a reference to the value corresponding to the key.
    ///
    /// The key may be any borrowed form of the map's key type, but
    /// [`Hash`] and [`Ord`] on the borrowed form *must* match those for
    /// the key type.
    ///
    /// [`Ord`]: std::cmp::Ord
    /// [`Hash`]: std::hash::Hash
    ///
    /// To obtain a `Guard`, use [`HashMap::guard`].
    ///
    /// # Examples
    ///
    /// ```
    /// use flurry::HashMap;
    /// use syncmap::Map;
    /// use syncmap::map::Map;
    ///
    /// let map = Map::new();
    /// let mref = map.pin();
    /// mref.insert(1, "a");
    /// assert_eq!(mref.get(&1), Some(&"a"));
    /// assert_eq!(mref.get(&2), None);
    /// ```
    #[inline]
    pub fn get<'g, Q>(&'g self, key: &Q, guard: &'g Guard<'_>) -> Option<&'g V>
        where
            K: Borrow<Q>,
            Q: ?Sized + Hash + Ord,
    {
        self.check_guard(guard);

        let read = self.read.load(Ordering::SeqCst, guard);
        if read.is_null() {
            return None;
        }
        let r = unsafe { read.deref() };
        let mut e = r.m.get(&key);
        if e.is_none() && r.amended {
            let lock = self.lock.lock();
            let read = self.read.load(Ordering::SeqCst, guard);
            let r = unsafe { read.deref() };
            e = r.m.get(&key);
            if e.is_none() && r.amended {
                let dirty = self.dirty.load(Ordering::SeqCst, guard);
                e = unsafe { dirty.deref() }.get(&key);
                self.miss_locked(guard);
            }
            drop(lock)
        }
        if e.is_none() {
            return None;
        }

        /*  let v = unsafe { Box::from_raw(e.unwrap().as_mut().unwrap()) };
          let p = v.p.load(Ordering::SeqCst, &guard);
          if p.is_null() {
              return None;
          }
          if let Some(p) = unsafe {p.as_ref()} {
              let v = &**p;
              return Some(v)
          }*/
        unsafe { e.unwrap().as_ref().unwrap().load(guard) }
    }


    fn miss_locked<'g>(&'g self, guard: &'g Guard) {
        self.misses.fetch_add(1, Ordering::SeqCst);
        let miss = self.misses.load(Ordering::SeqCst);
        let dirty = self.dirty.load(Ordering::SeqCst, guard);
        if dirty.is_null() {
            return;
        }
        if miss < unsafe { dirty.deref() }.len() {
            return;
        }
        let mut map = HashMap::new();

        for (key, value) in unsafe { dirty.deref() }.deref() {
            map.insert(key.clone(), *value);
        }
        let readOnluMap = Shared::boxed(ReadOnly {
            m: map,
            amended: false,
        }, &self.collector);
        let read = self.read.load(Ordering::SeqCst, guard);
        self.read.compare_exchange(read, readOnluMap, Ordering::AcqRel, Ordering::Acquire, guard);
        let old_map = self.dirty.load(Ordering::SeqCst, guard);
        if !old_map.is_null() {
            self.dirty.store(Shared::boxed(HashMap::new(), &self.collector), Ordering::SeqCst);
        }
        self.misses.compare_exchange(self.misses.load(Ordering::SeqCst), 0, Ordering::AcqRel, Ordering::Acquire);
    }
}


struct ReadOnly<K, V> {
    m: HashMap<K, *mut Entry<V>>,
    amended: bool,
}

impl<K, V> ReadOnly<K, V> {
    fn new() -> Self <> {
        Self {
            m: HashMap::new(),
            amended: false,
        }
    }
}
